{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X, y):\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=y)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    \"\"\"sigmoid function that accepts NumPy arrays\"\"\"\n",
    "\n",
    "    return 1.0 / ( 1.0 + np.e ** -x)\n",
    "\n",
    "\n",
    "\n",
    "def feed_forward(X, weights):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    1. calculate the dot product of X                 (N, 3)\n",
    "\n",
    "       and the weights of the first layer  (2, 3) --> (N, 2)\n",
    "\n",
    "    2. apply the sigmoid function on the result       (N, 2) return this\n",
    "\n",
    "    3. append an extra 1 for the bias to the result   (N, 3)\n",
    "\n",
    "    4. calculate the dot product of X\n",
    "\n",
    "       and the weights of the second layer (1, 3) --> (N, 1)\n",
    "\n",
    "    5. apply the sigmoid function on the result       (N, 1) return this\n",
    "\n",
    "    6. return intermediate results of the sigmoids\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d1 = np.dot(X, weights[0])\n",
    "\n",
    "    output1 = sigmoid(d1)\n",
    "\n",
    "    input2 = np.hstack([output1, np.ones((output1.shape[0], 1))])\n",
    "\n",
    "    d2 = np.dot(input2, weights[1])\n",
    "\n",
    "    output2 = sigmoid(d2)\n",
    "\n",
    "    return output1, output2\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(ytrue, ypred):\n",
    "\n",
    "    ypred = ypred.round().flatten().astype(np.int64)\n",
    "\n",
    "    return sum(ypred == ytrue) / y.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "def loss(ytrue, ypred):\n",
    "\n",
    "    \"\"\"Calculate the log loss\"\"\"\n",
    "\n",
    "    return -(ytrue * np.log(ypred) + (1 - ytrue) * np.log(1 - ypred))\n",
    "\n",
    "\n",
    "\n",
    "def get_weights():\n",
    "\n",
    "    weights = [\n",
    "\n",
    "        np.random.normal(size=(3, 2)),  # two neurons in the first layer\n",
    "\n",
    "        np.random.normal(size=(3, 1)),  # neuron in the second layer\n",
    "\n",
    "    ]\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def backpropagate(weights, out1, out2, X, ytrue, learning_rate=1.0):\n",
    "\n",
    "    ypred = out2.flatten()\n",
    "\n",
    "    error = (ypred - ytrue) * loss(ytrue, ypred)   # (N,)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate weight modification for output layer\n",
    "\n",
    "    grad_y = ypred * (1 - ypred) * error    # (N,)\n",
    "\n",
    "    out1_bias = np.hstack([out1, np.ones((out1.shape[0], 1))])\n",
    "\n",
    "    delta_wout = np.dot(-grad_y, out1_bias) * learning_rate\n",
    "\n",
    "    weights[1] += delta_wout.reshape((3,1))\n",
    "\n",
    "\n",
    "\n",
    "    # calculate weight modification for hidden layer\n",
    "\n",
    "    dp = np.dot(grad_y.reshape(50, 1), weights[1][:2].T)\n",
    "\n",
    "    grad_h = out1 * (1 - out1) * dp\n",
    "\n",
    "    delta_whiddden = np.dot(-grad_h.T, X) * learning_rate\n",
    "\n",
    "    weights[0] += delta_whiddden.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = make_moons(n_samples=50, noise=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# add an extra column for the bias\n",
    "\n",
    "X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    acc = 0.0\n",
    "\n",
    "    weights = get_weights()\n",
    "\n",
    "    while acc < 0.90:\n",
    "\n",
    "        out1, out2 = feed_forward(X, weights)\n",
    "\n",
    "        backpropagate(weights, out1, out2, X, y, learning_rate=0.1)\n",
    "\n",
    "        acc = accuracy(y, out2)\n",
    "\n",
    "        vloss = loss(y, out2.flatten())\n",
    "\n",
    "        print(f\"accuracy: {acc:5.2}   loss: {sum(vloss):8.5}\")\n",
    "\n",
    "        # break # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
